{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q gpt-2-simple\n",
    "# This code cell uses the pip package manager to install the gpt-2-simple library quietly (-q flag suppresses output) in the \n",
    "# current Python environment.gpt-2-simple is a Python package that provides a simplified interface for interacting with the GPT-2 language \n",
    "# model developed by OpenAI. This library allows users to fine-tune, generate text, and perform other tasks using GPT-2 \n",
    "# easily within their Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "\n",
    "# This code cell imports the gpt_2_simple library under the alias gpt2. By using the as keyword, the library can be \n",
    "# referred to using the shorter alias gpt2 throughout the code, making it more concise. Additionally, it imports the \n",
    "# datetime module from the Python standard library. The datetime module provides classes for manipulating dates and \n",
    "# times in both simple and complex ways. In this case, it's likely imported for time-related functionalities such as \n",
    "# logging or tracking when certain operations are performed.\n",
    "\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 851Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 3.42Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, ?it/s]                                                       \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:04, 7.70Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 773Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.86Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 4.84Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")\n",
    "\n",
    "#This code cell calls the download_gpt2() function from the gpt_2_simple library, which is used to download the GPT-2 model \n",
    "# specified by the model_name parameter. In this case, the model being downloaded is the 124M parameter version of GPT-2.\n",
    "# GPT-2 models are available in various sizes, denoted by the number of parameters they contain. The 124M model is one of \n",
    "# the smaller versions of GPT-2, containing 124 million parameters.\n",
    "\n",
    "#Downloading the model is necessary before using it for tasks such as text generation or fine-tuning on specific datasets. \n",
    "# Once downloaded, the model files are stored locally for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"C:\\\\Users\\\\lopez\\\\Documents\\\\ML Project\\\\shakespeare_sonnets_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lopez\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpt_2_simple\\gpt_2.py:215: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lopez\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpt_2_simple\\gpt_2.py:241: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Loading checkpoint models\\124M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models\\124M\\model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 26012 tokens\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 | 271.11] loss=4.16 avg=4.16\n",
      "[20 | 558.87] loss=3.57 avg=3.86\n",
      "[30 | 846.22] loss=3.30 avg=3.68\n",
      "[40 | 1132.82] loss=3.01 avg=3.51\n",
      "[50 | 1435.17] loss=2.44 avg=3.29\n",
      "======== SAMPLE 1 ========\n",
      "More I find that in these wastes I find nothing but thy smell\n",
      "Which I cannot see in another's world,\n",
      "To see, that I may taste thy self.\n",
      "In these wastes I have not the knowledge\n",
      "Which I may learn what I need, as in thy name;\n",
      "I shall be as thy scythe in beauty doth appear;\n",
      "And therefore thou art thine; for as in thy story, I must remain\n",
      "For thee this story, which tells of thine own state.\n",
      "The more I read of thy story, the more thou wilt,\n",
      "With a more true esteem, and a more virtuous heart.<|endoftext|>\n",
      "\n",
      "The story of youth will tell of thy youth,\n",
      "And youth, like a flower, will show thee that\n",
      "The stage hath shown thee this story.\n",
      "Look what beauty you will grant, and what bounteousness\n",
      "I require from your will, for I can no more grant\n",
      "Than youth's sweet smell. May my love, that thou mightest enjoy\n",
      "Than this flower that doth seem, show thy gift;\n",
      "Hence, my love, thou lov'st this, too.\n",
      "For I love, and you love, and I desire\n",
      "To be, and in that want, to be admired;\n",
      "So I have made you one with mine own beauty,\n",
      "And I like that which you have made one.<|endoftext|>\n",
      "\n",
      "O! my love! keep still, till I will put a stop to thee,\n",
      "And love, for you are so, in me I need give;\n",
      "But since with your love and I be deemed one,\n",
      "Then let love give thee one respect: then will I not be able\n",
      "To make other love give thee the respect I deserve?\n",
      "How can I be virtuous when in you,\n",
      "When I am truly your slave? what shall I make of thee\n",
      "And how shall loving-kindred love-kindred boast?\n",
      "Nay, for you made me one with mine own worth;\n",
      "What is my worth to you, if thou lov'st me not?\n",
      "What do I want of thee, if thou give my wish?\n",
      "What do I want after that whose name I can tell\n",
      "That tells of yours' lives, how well I live?\n",
      "How long have I lived in thee! from those walls\n",
      "That bear me to these days to these proud dates\n",
      "Before thee date the year to come.<|endoftext|>\n",
      "\n",
      "Who am I in the world, though never one?\n",
      "O! that which stands in my way, my love,\n",
      "Him how can I inhabit it now that I be?\n",
      "What can I do, my love, if I never be found?\n",
      "O! what shall I live for, if ever I be found?\n",
      "What can live for in that which sits before\n",
      "My lips, when at the very base of my thought\n",
      "Received I th' inconstant conquest? what can live even\n",
      "That in my spirit when it is made known to my heart?\n",
      "How can my spirit then live when my heart\n",
      "Makes itself known to me, and my heart itself is made unread;\n",
      "And yet I can still live, for in it be built\n",
      "Nativity, born of itself, beauty which is in part\n",
      "Named, and to that beauty in beauty gives life,\n",
      "Making it seem to me so, that this alone\n",
      "Is enough; but what else shall I live for?\n",
      "Him, whose heart have I made of my love,\n",
      "And what other part of it then is to my sight?\n",
      "O! what more can I live on my love than that\n",
      "Which is made known to me above form?\n",
      "Who can say, that I am a living one?\n",
      "When I am, how can I be thought a dead one?\n",
      "When I am, how can I live out this life?\n",
      "When I am, how can I live out this death?\n",
      "When I am, how can I live out this hell?\n",
      "When I am, how can I live out death out of sight?\n",
      "When I am, how can I live out this hell out of mind?\n",
      "When I am, how can I live this hell out of control?\n",
      "Where in hell is my heart that keeps on moving,\n",
      "Howling all at once before me, even to the shore\n",
      "Which lays heavy siege on me?\n",
      "How can I, who in mine heart is moving,\n",
      "Feed on that which I in my heart can hold off?\n",
      "Who can vaunt that which he in my heart puts first?\n",
      "When I, who in mine heart dwells on moving,\n",
      "Feed on my heart, my heart to use, to transport it?\n",
      "Him that I love, loves to use; loves nothing else\n",
      "As a chest-maid, nor can I, wanting to leave her,\n",
      "Save where she lies, with her breast on me,\n",
      "\n",
      "[60 | 1803.76] loss=2.32 avg=3.12\n",
      "[70 | 2098.21] loss=1.69 avg=2.91\n",
      "[80 | 2395.57] loss=1.48 avg=2.73\n",
      "[90 | 2693.52] loss=0.73 avg=2.50\n",
      "[100 | 2948.61] loss=0.55 avg=2.29\n",
      "Saving checkpoint\\run1\\model-100\n"
     ]
    }
   ],
   "source": [
    "#This line initializes a TensorFlow session for running the GPT-2 model.\n",
    "sess = gpt2.start_tf_sess()\n",
    "# restore_from = set to fresh to start training from the base GPT-2 or set to latest to restart training from an existing checkpoint\n",
    "# sample_every = number of steps to print example output\n",
    "# print_every = number of steps to print training progress\n",
    "# learning_rate = learning rate for the training (default: 1e-4, can lower to 1e-5 if you have\n",
    "# run_name = subfolder within checkpoint to save the model\n",
    "# overwrite = set to true if you want to continue finetuning an existing model without create duplicate copies\n",
    "\n",
    "#This session will be used throughout the fine-tuning process.\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=100,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=50,\n",
    "              save_every=100)\n",
    "\n",
    "#This code cell essentially starts a TensorFlow session, fine-tunes the GPT-2 model on a specified dataset for 100 steps, \n",
    "# and periodically prints the training progress and generates example output. The fine-tuned model checkpoints are saved \n",
    "# under the specified run_name subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint C:\\Users\\lopez\\Documents\\ML Project\\checkpoint\\run1\\model-100\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\lopez\\Documents\\ML Project\\checkpoint\\run1\\model-100\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, reuse=True, checkpoint_dir='C:\\\\Users\\\\lopez\\\\Documents\\\\ML Project\\\\checkpoint')\n",
    "# This function call loads a pre-trained GPT-2 model into the TensorFlow session.\n",
    "#reuse=True: This parameter indicates whether to reuse variables from the loaded model. Setting it to True allows reusing the model for further tasks\n",
    "#This code cell demonstrates loading a pre-trained GPT-2 model using the gpt_2_simple library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Poem:\n",
      "i hate you\n",
      "To whom my verse graces your heart;\n",
      "And all my poor love to-day unfathered\n",
      "In an ever-dreary world of poverty,\n",
      "Poor you, but not still. Dear me, thou art so,\n",
      "That all my favourites, all my fresco's true,\n",
      "Hath thee, and now I know thee well:\n",
      "For me thee'sw ere thou were made free,\n",
      "A slave to slavery, whose freedom was death:\n",
      "Yet thou, whom I cast free, liveth, and deserve,\n",
      "Like a free babe, in thee all my time.\n",
      "Thus do I wish thee well, my dear, love;\n",
      "And, dear, do not let that aspiring song,\n",
      "Which tells the age's young to like to be gone,\n",
      "Save what a true character thou wouldst have thee:\n",
      "Then would I like thee, but in this my voice\n",
      "I sing not to sell thee, but to give thee thee:\n",
      "Thus would I live, though not in thee, but in thee were sung,\n",
      "The barren tender whom thee doth give nursing:\n",
      "For thou, whom I have given life to, live'st thou again;\n",
      "And life, if\n"
     ]
    }
   ],
   "source": [
    "# Function to generate poem based on user input\n",
    "def generate_poem(prompt):\n",
    "    # Generate poem using user input as prefix\n",
    "    poem = gpt2.generate(sess,\n",
    "                         length=250,\n",
    "                         temperature=0.9,\n",
    "                         top_k=40,\n",
    "                         top_p=0.9,\n",
    "                         prefix=prompt,\n",
    "                         truncate='<|endoftext|',\n",
    "                         nsamples=1,\n",
    "                         batch_size=1,\n",
    "                         return_as_list=True)[0]\n",
    "    return poem\n",
    "\n",
    "# Prompt user for input\n",
    "user_input = input(\"Enter a prompt to generate a poem: \")\n",
    "\n",
    "# Generate poem based on user input\n",
    "poem = generate_poem(user_input)\n",
    "\n",
    "# Print the generated poem\n",
    "print(\"Generated Poem:\")\n",
    "print(poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
